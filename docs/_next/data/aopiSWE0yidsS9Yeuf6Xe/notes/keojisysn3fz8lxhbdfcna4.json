{"pageProps":{"note":{"id":"keojisysn3fz8lxhbdfcna4","title":"Artificial Intelligence (AI)","desc":"","updated":1663751768488,"created":1663751303455,"custom":{},"fname":"ai","type":"note","vault":{"fsPath":".","selfContained":true,"name":"exam-notes"},"contentHash":"3ad06c758c1fa47a97e9ba5e77b3907d","links":[],"anchors":{"linear-algebra--regression--classification":{"type":"header","text":"Linear Algebra , Regression & Classification","value":"linear-algebra--regression--classification","line":28,"column":0,"depth":2},"linear-regression":{"type":"header","text":"Linear Regression","value":"linear-regression","line":34,"column":0,"depth":2},"what-is-pytorch-tensor-":{"type":"header","text":"What is PyTorch Tensor ??","value":"what-is-pytorch-tensor-","line":40,"column":0,"depth":3},"batch-sizes":{"type":"header","text":"Batch Sizes","value":"batch-sizes","line":45,"column":0,"depth":3},"in-the-neural-network-terminology":{"type":"header","text":"In the neural network terminology:","value":"in-the-neural-network-terminology","line":50,"column":0,"depth":3},"shuffles":{"type":"header","text":"Shuffles","value":"shuffles","line":58,"column":0,"depth":3},"layers-hand-drawn-numbers-training":{"type":"header","text":"Layers (Hand Drawn Numbers training)","value":"layers-hand-drawn-numbers-training","line":62,"column":0,"depth":3},"feed-forward":{"type":"header","text":"Feed Forward","value":"feed-forward","line":68,"column":0,"depth":3},"training-model":{"type":"header","text":"Training Model","value":"training-model","line":83,"column":0,"depth":3},"neural-net-from-scratch":{"type":"header","text":"Neural net from scratch","value":"neural-net-from-scratch","line":91,"column":0,"depth":3}},"children":[],"parent":"gjr379x4uby1klukcwuuafc","data":{}},"body":"<h1 id=\"artificial-intelligence-ai\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#artificial-intelligence-ai\"></a>Artificial Intelligence (AI)</h1>\n<p>Machine Learning is a iterative process.</p>\n<p><strong>Supervised Learning</strong> :\nThere is a direct relationship between input variable &#x26; output variable. Check the drawing below to understand more :\n<img src=\"/exam-notes/assets/images/2022-09-21-14-39-10.png\"></p>\n<p><strong>Supervised learning</strong> problems can be classified into :</p>\n<ul>\n<li>\n<p><em>regression problem</em> : Data itself is predicted. Example :House price prediction</p>\n</li>\n<li>\n<p><em>classification problem</em> : Category is predicted by the data. Example : if we upload an image of an animal then whether that animal is cat or non cat .</p>\n</li>\n</ul>\n<p><strong><em>Anomaly detection algorithm</em></strong> : Identify unusal data points. Example : Unusal traffic or strange patterns in network that can indicate network is hacked.</p>\n<p><strong><em>Clustering algorithm</em></strong> : Groups data based on similiar conditions. Example : what types of customer buys a certain product</p>\n<p><strong>Overfitting Data</strong> : When model tries to use all attributes (even the least important ones) due to excess knowledge of attributes training set score is increasing (or error is decreasing) while testing set score is decreasing (or error is increasing)</p>\n<p><strong>Underfitting Data</strong> : model doesn't has enough knowledge and gives results which have very less connections/harmony among each other , due to lack of enough attributes.</p>\n<h2 id=\"linear-algebra--regression--classification\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#linear-algebra--regression--classification\"></a>Linear Algebra , Regression &#x26; Classification</h2>\n<p>Scalar,Vector,Matrix,Matrix Operations,Norms,Probaility,Joint Distribution,Bayes theorem , Expectation, COvariance.</p>\n<p>Vector dot product = each row * each column</p>\n<h2 id=\"linear-regression\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#linear-regression\"></a>Linear Regression</h2>\n<hr>\n<p>Read this to learn more about <a href=\"https://realpython.com/python-virtual-environments-a-primer/#why-do-you-need-virtual-environments\">Why Virtual Environments</a></p>\n<h3 id=\"what-is-pytorch-tensor-\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#what-is-pytorch-tensor-\"></a>What is PyTorch Tensor ??</h3>\n<p>A Pytorch Tensor is just a generic <strong>n-dimensional array</strong> to be used for arbitrary numeric computation. It can run on either CPU or GPU.\nRead this article to learn more : <a href=\"https://www.geeksforgeeks.org/tensors-in-pytorch/\">Tensors in PyTorch</a></p>\n<h3 id=\"batch-sizes\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#batch-sizes\"></a>Batch Sizes</h3>\n<p>For example I have 1000 samples of data for training &#x26; I set batch_size = 10 then first 10 data samples (i.e from 1 to 10 ) will be used to train. Then again next 10 data samples (i.e from 11 to 20) will be used to train. Simliarly all 100 datat samples will be trained by training 10 samples at once.\nGradient descent is an optimization algorithm used to find the values of parameters (coefficients) of a function (f) that minimizes a cost function (cost). Gradient descent is best used when the parameters cannot be calculated analytically (e.g. using linear algebra) and must be searched for by an optimization algorithm.</p>\n<h3 id=\"in-the-neural-network-terminology\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#in-the-neural-network-terminology\"></a>In the neural network terminology:</h3>\n<ul>\n<li><em>one epoch</em> = one forward pass and one backward pass of all the training examples</li>\n<li><em>batch size</em> = the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.</li>\n<li><em>number of iterations</em> = number of passes, each pass using batch size as number of examples. To be clear, one pass = one forward pass + one backward pass (we do not count the forward pass and backward pass as two different passes).</li>\n</ul>\n<p>Example: if you have 1000 training examples, and your batch size is 500, then it will take 2 iterations to complete 1 epoch.</p>\n<h3 id=\"shuffles\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#shuffles\"></a>Shuffles</h3>\n<p>For Example ,We want our neural net to recognize each number from the hand drawings &#x26; we are using a dataset that has all handdrawn numbers form 0 to 9 to train the net. Now if we took a neural net &#x26; fed through a bunch of 0s 1st then the neural net will say all are 0s , then when we fed 1s then the neural net will say all are 1s &#x26; when we reach 9s then it will end saying all are 9s. Now it will only recognize 9s but not the previous numbers but we want the net to recognize each number. Shuffling will make sure it learns all the numbers by trying to learn all numbers together.</p>\n<h3 id=\"layers-hand-drawn-numbers-training\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#layers-hand-drawn-numbers-training\"></a>Layers (Hand Drawn Numbers training)</h3>\n<p>We are trying to have 3 hidden layers of 64 neurons. First layer will have Input of <code>28*28</code> (image size) &#x26; out put will be 64.Then next 2 layers will have 64 as both input &#x26; output sizes. Then the last layer will have input of 64 but output will be 10 . The 2nd , 3rd ,4th layer's input is 64 because the prev layer outputs 64 &#x26; this 64 then gets inputted to this layer.The 4th layer outputs 10 beacuse hand drawn numbers have 0 to 9 numbers (10 numbers in total) so 10 classes will be outputted.</p>\n<p><img src=\"/exam-notes/assets/images/2022-09-21-14-41-30.png\"></p>\n<h3 id=\"feed-forward\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#feed-forward\"></a>Feed Forward</h3>\n<p>In the prev section we created some layers now we need a path to take data from each layer to another. A feedforward neural network (FNN) is an artificial neural network wherein connections between the nodes do not form a cycle. The feedforward neural network was the first and simplest type of artificial neural network devised.</p>\n<p><img src=\"/exam-notes/assets/images/2022-09-21-14-41-51.png\"></p>\n<p><img src=\"/exam-notes/assets/images/2022-09-21-14-42-07.png\"></p>\n<p>X will be passed to each layer however our model wont learn much because data wont be scaled properly. Scaled properly means data is transformed such that the features are within a specific range e.g. [0, 1]. For proper data scaling we need <a href=\"https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6\">activation functions</a>. So here we will use ReLU activation. Activation Functions work on output of layers. So for the 1st 3 layers we will use ReLU Activation Functions but for the 4th layer we will use something else.\n4th layer has 10 neurons (0-9 numbers) so we want to optimize the output so that 1 neuron is fully fired than the other 9. For that we will use softmax.</p>\n<p><img src=\"/exam-notes/assets/images/2022-09-21-14-43-00.png\"></p>\n<p>Notice that in the above image I have a forward method. This forward is called when Net Model is called (in line : <code>output=net(X)</code> ) . When you call the model directly this Forward is called , the internal  <code>__call__</code>  function is used. This function manages all registered hooks and calls forward afterwards. That’s also the reason you should call the model directly, because otherwise your hooks might not work etc.</p>\n<h3 id=\"training-model\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#training-model\"></a>Training Model</h3>\n<p>Loss &#x26; optimizer are needed to make sure the model is nearly accurate. Loss means how wrong the model is. Optimizer makes sure the loss is reduced slowly over time based on the learning rate.</p>\n<p>When we pass data through the neural network , it incurs a loss. Now it is entirely calculable to get weights to make loss zero. If we do that then our model might. So we use learning rate to opimize to lower the loss but only take certain size steps to opimize(not gigantic steps because then the optimization might stuck).</p>\n<p><img src=\"/exam-notes/assets/images/2022-09-21-14-43-36.png\"></p>\n<h3 id=\"neural-net-from-scratch\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#neural-net-from-scratch\"></a>Neural net from scratch</h3>\n<p>Let A0 be the input layer, Z1 &#x26; Z2 be the unactivated hidden layer. We will get the dot product of W1 and A0. W1 is bunch of weights that correspond to each of the 7840 connections. b1 is a constant bias term added to each of the 10 nodes. Then we will add activation functions to Z1.\nWithout applying activation function each node in the 1st layer would be <em>a linear combination of nodes before it + bias term</em> . Then the second layer will be a linear combo of 1st layer &#x26; finally the output layer will be linear combo of 2nd layer which is a linear combo of 1st layer which is linear combo of input layer. This is just a fancy linear regression &#x26; will not become a smart learner. For more info <a href=\"https://qr.ae/pvOVWB\">read this</a></p>\n<p><img src=\"/exam-notes/assets/images/2022-09-21-14-44-02.png\"></p>\n<p>We will use Rectified Linear Unit. A1 is the ==output== of ReLU applied on Z1. Then in similiar fashion we will get Z2 which is the second layer of hidden layers. However we will use Softmax activation function on Z2 to get the output layer (A2) .</p>\n<p><img src=\"/exam-notes/assets/images/2022-09-21-14-44-34.png\"></p>","noteIndex":{"id":"gjr379x4uby1klukcwuuafc","title":"Root","desc":"","updated":1663749110634,"created":1663740327223,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":".","selfContained":true,"name":"exam-notes"},"contentHash":"f0577dcf4f8c635682dea6fed1600903","links":[],"anchors":{"notes-taken-by-abhik-b-for-competitive-exams":{"type":"header","text":"Notes taken by Abhik B for competitive exams","value":"notes-taken-by-abhik-b-for-competitive-exams","line":8,"column":0,"depth":1}},"children":["keojisysn3fz8lxhbdfcna4","nx2wuyeo5kgob0u4jucsers","gx0wes5gz0irclfjvffusa4"],"parent":null,"data":{},"body":"\n# Notes taken by Abhik B for competitive exams\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true,"enableSelfContainedVaults":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":".","selfContained":true,"name":"exam-notes"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"task","dateFormat":"y.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"taskCompleteStatus":["done","x"],"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableFullHierarchyNoteTitle":false,"enableSmartRefs":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"assetsPrefix":"/exam-notes","siteUrl":"https://abhik-b.github.io","siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Abhik B's Exam Notes","description":"Notes taken while studying computer applications"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true}