{"pageProps":{"note":{"id":"teaqsmbxeubw47kp104doko","title":"Machine Learning","desc":"","updated":1666703784985,"created":1666181626213,"custom":{},"fname":"ml","type":"note","vault":{"fsPath":".","selfContained":true,"name":"exam-notes"},"contentHash":"ef36bf5a01d1e5de4ce418c6e69e2ee5","links":[],"anchors":{"linear-algebra--classification":{"type":"header","text":"Linear Algebra & Classification","value":"linear-algebra--classification","line":27,"column":0,"depth":2},"least-square-method":{"type":"header","text":"Least Square Method","value":"least-square-method","line":33,"column":0,"depth":3},"gradient-descent":{"type":"header","text":"Gradient Descent","value":"gradient-descent","line":40,"column":0,"depth":3}},"children":["9t5w8vr9crcq66hrljywspb"],"parent":"gjr379x4uby1klukcwuuafc","data":{}},"body":"<h1 id=\"machine-learning\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#machine-learning\"></a>Machine Learning</h1>\n<p>Machine Learning is a iterative process.</p>\n<p><strong>Supervised Learning</strong> :\nThere is a direct relationship between input variable &#x26; output variable. Check the drawing below to understand more :\n<img src=\"/exam-notes/assets/images/2022-09-21-14-39-10.png\"></p>\n<p><strong>Supervised learning</strong> problems can be classified into :</p>\n<ul>\n<li>\n<p><em>regression problem</em> : Data itself is predicted. Example :House price prediction</p>\n</li>\n<li>\n<p><em>classification problem</em> : Category is predicted by the data. Example : if we upload an image of an animal then whether that animal is cat or non cat .</p>\n</li>\n</ul>\n<p><strong><em>Anomaly detection algorithm</em></strong> : Identify unusal data points. Example : Unusal traffic or strange patterns in network that can indicate network is hacked.</p>\n<p><strong><em>Clustering algorithm</em></strong> : Groups data based on similiar conditions. Example : what types of customer buys a certain product</p>\n<p><strong>Overfitting Data</strong> : When model tries to use all attributes (even the least important ones) due to excess knowledge of attributes training set score is increasing (or error is decreasing) while testing set score is decreasing (or error is increasing)</p>\n<p><strong>Underfitting Data</strong> : model doesn't has enough knowledge and gives results which have very less connections/harmony among each other , due to lack of enough attributes.</p>\n<h2 id=\"linear-algebra--classification\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#linear-algebra--classification\"></a>Linear Algebra &#x26; Classification</h2>\n<p>Vector dot product = each row * each column</p>\n<h3 id=\"least-square-method\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#least-square-method\"></a>Least Square Method</h3>\n<p>The least squares method is a form of mathematical regression analysis used to determine the line of best fit for a set of data, providing a visual demonstration of the relationship between the data points. Each point of data represents the relationship between a known independent variable and an unknown dependent variable.</p>\n<ul>\n<li>The least squares method is a statistical procedure to find the best fit for a set of data points by minimizing the sum of the offsets or residuals of points from the plotted curve.</li>\n<li>Least squares regression is used to predict the behavior of dependent variables.</li>\n<li>The least squares method provides the overall rationale for the placement of the line of best fit among the data points being studied.\nLearn more <a href=\"https://www.investopedia.com/terms/l/least-squares-method.asp\">here</a></li>\n</ul>\n<h3 id=\"gradient-descent\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#gradient-descent\"></a>Gradient Descent</h3>\n<p>Gradient descent (GD) is an iterative first-order optimisation algorithm used to find a local minimum/maximum of a given function. This method is commonly used in machine learning (ML) and deep learning(DL) to minimise a cost/loss function (e.g. in a linear regression). Due to its importance and ease of implementation, this algorithm is usually taught at the beginning of almost all machine learning courses.\nLearn <a href=\"https://towardsdatascience.com/gradient-descent-algorithm-a-deep-dive-cf04e8115f21\">more</a></p>\n<hr>\n<strong>Children</strong>\n<ol>\n<li><a href=\"/exam-notes/notes/9t5w8vr9crcq66hrljywspb\">Regression</a></li>\n</ol>","noteIndex":{"id":"gjr379x4uby1klukcwuuafc","title":"Root","desc":"","updated":1664424403234,"created":1663740327223,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":".","selfContained":true,"name":"exam-notes"},"contentHash":"57c801f96fa00329063b52177f8e4b08","links":[],"anchors":{"notes-taken-by-abhik-b-for-competitive-exams":{"type":"header","text":"Notes taken by Abhik B for competitive exams","value":"notes-taken-by-abhik-b-for-competitive-exams","line":8,"column":0,"depth":1}},"children":["keojisysn3fz8lxhbdfcna4","nx2wuyeo5kgob0u4jucsers","gx0wes5gz0irclfjvffusa4","u8o7ksndu0na9g910fuglx5","teaqsmbxeubw47kp104doko","4t4frfo11yj7dr8558kdhr1"],"parent":null,"data":{},"body":"\n# Notes taken by Abhik B for competitive exams\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true,"enableSelfContainedVaults":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":".","selfContained":true,"name":"exam-notes"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"task","dateFormat":"y.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"taskCompleteStatus":["done","x"],"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableFullHierarchyNoteTitle":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"assetsPrefix":"/exam-notes","siteUrl":"https://abhik-b.github.io","siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Abhik B's Exam Notes","description":"Notes taken while studying computer applications"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"siteFaviconPath":"favicon.ico","siteIndex":"root","searchMode":"lookup"}}},"__N_SSG":true}